{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "tpn-CttJYacG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assamese_path = '/home/ml/nlp/NLP/as.txt'\n",
        "bengali_path = '/home/ml/nlp/NLP/bn.txt'\n",
        "english_path = '/home/ml/nlp/NLP/en.txt'\n",
        "gujrati_path = '/home/ml/nlp/NLP/gu.txt'\n",
        "hindi_path= '/home/ml/nlp/NLP/hi.txt'\n",
        "malyalam_path = '/home/ml/nlp/NLP/ml.txt'\n",
        "marathi_path = '/home/ml/nlp/NLP/mr.txt'\n",
        "oriya_path = '/home/ml/nlp/NLP/or.txt'\n",
        "punjabi_path = '/home/ml/nlp/NLP/pa.txt'\n",
        "tamil_path = '/home/ml/nlp/NLP/ta.txt'\n",
        "telugu_path = '/home/ml/nlp/NLP/te.txt'"
      ],
      "metadata": {
        "id": "OZh7WrPulYSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the text files\n",
        "with open(assamese_path, 'r', encoding='latin-1') as file:\n",
        "    assamese_data = file.readlines()\n",
        "\n",
        "with open(bengali_path, 'r', encoding='latin-1') as file:\n",
        "    bengali_data = file.readlines()\n",
        "\n",
        "with open(english_path, 'r', encoding='latin-1') as file:\n",
        "    english_data = file.readlines()\n",
        "\n",
        "with open(gujrati_path, 'r', encoding='latin-1') as file:\n",
        "    gujrati_data = file.readlines()\n",
        "\n",
        "with open(hindi_path, 'r', encoding='latin-1') as file:\n",
        "    hindi_data = file.readlines()\n",
        "\n",
        "with open(malyalam_path, 'r', encoding='latin-1') as file:\n",
        "    malyalam_data = file.readlines()\n",
        "\n",
        "with open(marathi_path, 'r', encoding='latin-1') as file:\n",
        "    marathi_data = file.readlines()\n",
        "\n",
        "with open(oriya_path, 'r', encoding='latin-1') as file:\n",
        "    oriya_data = file.readlines()\n",
        "\n",
        "with open(punjabi_path, 'r', encoding='latin-1') as file:\n",
        "    punjabi_data = file.readlines()\n",
        "\n",
        "with open(tamil_path, 'r', encoding='latin-1') as file:\n",
        "    tamil_data = file.readlines()\n",
        "\n",
        "with open(telugu_path, 'r', encoding='latin-1') as file:\n",
        "    telugu_data = file.readlines()"
      ],
      "metadata": {
        "id": "iU9AsFL8lalA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine data\n",
        "all_data = assamese_data + bengali_data + english_data + gujrati_data + hindi_data + malyalam_data + marathi_data + oriya_data + punjabi_data + tamil_data + telugu_data\n",
        "\n",
        "labels = ['assamese'] * len(assamese_data) + ['bengali'] * len(bengali_data) + ['english'] * len(english_data) + ['gujrati'] * len(gujrati_data) +['hindi'] * len(hindi_data) +\n",
        " ['malyalam'] * len(malyalam_data) + ['marathi'] * len(marathi_data) + ['oriya'] * len(oriya_data) + ['punjabi'] * len(punjabi_data) + ['tamil'] * len(tamil_data) +\n",
        " ['telugu'] * len(telugu_data)"
      ],
      "metadata": {
        "id": "gjj2eoxNqQOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(all_data, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "qWhvgZhGqWnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the text data\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "ERr3YrMaqXRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_vec, y_train)"
      ],
      "metadata": {
        "id": "hbo9BA-oqZzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "y_pred = model.predict(X_test_vec)"
      ],
      "metadata": {
        "id": "_ufh8P3VqcF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "TrSgAO9IOl4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(assamese_path, oriya_path):\n",
        "      # Read the text files\n",
        "    with open(assamese_path, 'r', encoding='latin-1') as file:\n",
        "        assamese_data = file.readlines()\n",
        "\n",
        "    with open(bengali_path, 'r', encoding='latin-1') as file:\n",
        "        bengali_data = file.readlines()\n",
        "\n",
        "    with open(english_path, 'r', encoding='latin-1') as file:\n",
        "        english_data = file.readlines()\n",
        "\n",
        "    with open(gujrati_path, 'r', encoding='latin-1') as file:\n",
        "        gujrati_data = file.readlines()\n",
        "\n",
        "    with open(hindi_path, 'r', encoding='latin-1') as file:\n",
        "        hindi_data = file.readlines()\n",
        "\n",
        "    with open(malyalam_path, 'r', encoding='latin-1') as file:\n",
        "        malyalam_data = file.readlines()\n",
        "\n",
        "    with open(marathi_path, 'r', encoding='latin-1') as file:\n",
        "        marathi_data = file.readlines()\n",
        "\n",
        "    with open(oriya_path, 'r', encoding='latin-1') as file:\n",
        "        oriya_data = file.readlines()\n",
        "\n",
        "    with open(punjabi_path, 'r', encoding='latin-1') as file:\n",
        "        punjabi_data = file.readlines()\n",
        "\n",
        "    with open(tamil_path, 'r', encoding='latin-1') as file:\n",
        "        tamil_data = file.readlines()\n",
        "\n",
        "    with open(telugu_path, 'r', encoding='latin-1') as file:\n",
        "        telugu_data = file.readlines()\n",
        "\n",
        "    # Combine data\n",
        "    all_data = assamese_data + bengali_data + english_data + gujrati_data + hindi_data + malyalam_data + marathi_data + oriya_data + punjabi_data + tamil_data + telugu_data\n",
        "\n",
        "    labels = ['assamese'] * len(assamese_data) + ['bengali'] * len(bengali_data) + ['english'] * len(english_data) + ['gujrati'] * len(gujrati_data) +['hindi'] * len(hindi_data) +\n",
        "    ['malyalam'] * len(malyalam_data) + ['marathi'] * len(marathi_data) + ['oriya'] * len(oriya_data) + ['punjabi'] * len(punjabi_data) + ['tamil'] * len(tamil_data) +\n",
        "    ['telugu'] * len(telugu_data)\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(all_data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create a pipeline with CountVectorizer and MultinomialNB\n",
        "    model = Pipeline([\n",
        "        ('vectorizer', CountVectorizer()),\n",
        "        ('classifier', MultinomialNB())\n",
        "    ])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "iq2ALimhGauA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZCdEJ1ULyHW"
      },
      "outputs": [],
      "source": [
        "def predict_language(model, file_path):\n",
        "    # Read the text file\n",
        "    with open(file_path, 'r', encoding='latin-1') as file:\n",
        "        data = file.read()\n",
        "\n",
        "    # Predict the language\n",
        "    prediction = model.predict([data])[0]\n",
        "\n",
        "    return prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model = train_model('/content/drive/MyDrive/NLP/as.txt', '/home/ml/nlp/NLP/bn.txt', '/home/ml/nlp/NLP/en.txt', '/home/ml/nlp/NLP/gu.txt', '/home/ml/nlp/NLP/hi.txt', '/home/ml/nlp/NLP/ml.txt', '/home/ml/nlp/NLP/mr.txt', '/home/ml/nlp/NLP/or.txt', '/home/ml/nlp/NLP/pa.txt', '/home/ml/nlp/NLP/ta.txt', '/home/ml/nlp/NLP/te.txt')"
      ],
      "metadata": {
        "id": "v9dYOw0qGe7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage of predict_language function\n",
        "prediction = predict_language(model, '/content/drive/MyDrive/NLP/prediction.txt')\n",
        "print(\"Predicted Language:\", prediction)"
      ],
      "metadata": {
        "id": "Jg3red9WGhTv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}